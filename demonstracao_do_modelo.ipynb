{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariafernanda0011/Classificador-CNH/blob/main/demonstracao_do_modelo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74aa844f"
      },
      "source": [
        "# **Demonstração de Classificação de Documentos - CNH física e digital**\n",
        "\n",
        "> Este notebook permite **testar o modelo de classificação de documentos** já treinado.  \n",
        "Ele carrega o modelo salvo, processa uma imagem enviada pelo usuário e exibe a classe prevista.\n",
        "\n",
        "\n",
        "### **Faça upload para este notebook dos seguintes arquivos da pasta `processamento` (presentes no repositório):**\n",
        "[Classificador de CNH](https://github.com/mariafernanda0011/Classificador-CNH.git)\n",
        "\n",
        "- `extract_features.py`  \n",
        "- `qr_feature_extractor.py`  \n",
        "- `color_feature_extractor.py`\n",
        "\n",
        "Eles são necessários para extrair texto, QR Code e cores da imagem.\n",
        "\n",
        "### **Você também deve enviar o arquivo do modelo que deseja testar.**\n",
        "- `xgboost_cnh_classifier.pkl`\n",
        "- `random_forest_cnh_classifier.plk`\n",
        "- `naive_bayes_cnh_classifier.plk`\n",
        "\n",
        "### **Não se esqueça também de anexar a imagem que você quer classificar, altere a descrição da imagem atribuida na etapa 2, que faz o carregamento da imagem.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34890c78"
      },
      "source": [
        "# Importando bibliotecas necessárias\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib # Importar joblib para carregar o modelo .pkl\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import xgboost as xgb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1e6a806"
      },
      "source": [
        "#### **1. Carregar o Modelo Salvo**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = joblib.load('xgboost_cnh_classifier.pkl')\n",
        "model = joblib.load('naive_bayes_cnh_classifier.pkl')\n",
        "#model = joblib.load('random_forest_cnh_classifier.pkl')"
      ],
      "metadata": {
        "id": "6G43rPtYnQAg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2. Carregando a imagem**"
      ],
      "metadata": {
        "id": "FkTGV3DZo6TH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38ea494d",
        "outputId": "2603b299-0f96-4844-eaec-a41ff9fcd18a"
      },
      "source": [
        "img_path = 'nome_da_sua_img.jpg'\n",
        "\n",
        "# Carregar a imagem\n",
        "image_to_process = Image.open(img_path)\n",
        "print(f\"Imagem '{img_path}' carregada com sucesso. Formato: {image_to_process.format}, Tamanho: {image_to_process.size}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagem 'cnh_ed.jpg' carregada com sucesso. Formato: JPEG, Tamanho: (1200, 1600)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3. Extraindo features e Testando o modelo**"
      ],
      "metadata": {
        "id": "dFiy78HVxDC5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e6ca53b",
        "outputId": "a35177d0-08e8-4d08-a8fa-fb55dd1384aa"
      },
      "source": [
        "print(\"Instalando tesseract-ocr e pytesseract...\")\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y tesseract-ocr\n",
        "!pip install pytesseract\n",
        "\n",
        "import pytesseract\n",
        "pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n",
        "\n",
        "print(\"Concluido.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instalando tesseract-ocr e pytesseract...\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 48 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (11.3.0)\n",
            "Concluido.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from extract_features import extrair_texto, contar_palavras, processar_imagem, obter_bag_palavras, gerar_features_bag_palavras, gerar_csv\n",
        "from qr_feature_extractor import detectar_qr\n",
        "from color_feature_extractor import get_colors_hsv, generate_color_features"
      ],
      "metadata": {
        "id": "EVGgclvmzOas"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Extrair texto (OCR) da imagem e conta palavras\n",
        "resultado = processar_imagem(img_path)\n",
        "print(\"Imagem processada.\")\n",
        "\n",
        "# 3. Detectar QR Code\n",
        "resultado[\"qr_detectado\"] = detectar_qr(img_path)\n",
        "\n",
        "# 4. Extrair características de cor\n",
        "hsv_colors = get_colors_hsv(img_path)\n",
        "color_features_dict = generate_color_features(hsv_colors)\n",
        "resultado.update(color_features_dict)\n",
        "\n",
        "df = pd.DataFrame([resultado])\n",
        "\n",
        "# Gerar Bag of Words Features\n",
        "df = gerar_features_bag_palavras(df, obter_bag_palavras())\n",
        "\n",
        "# Correção: Chamar o método .drop() com parênteses e especificar o parâmetro 'columns'\n",
        "X = df.drop(columns=[\"nome_arquivo\", \"texto_extraido\"])\n",
        "\n",
        "#modelo = joblib.load(\"xgboost_cnh_classifier.pkl\")\n",
        "modelo = joblib.load(\"naive_bayes_cnh_classifier.pkl\")\n",
        "#modelo = joblib.load(\"random_forest_cnh_classifier.pkl\")\n",
        "\n",
        "pred = modelo.predict(X)\n",
        "classe_predita = int(pred[0])\n",
        "\n",
        "class_labels = {\n",
        "    0: \"CNH digital - aberta\",\n",
        "    1: \"CNH digital - frente\",\n",
        "    2: \"CNH digital - verso\",\n",
        "    3: \"CNH fisica - aberta\",\n",
        "    4: \"CNH fisica - frente\",\n",
        "    5: \"CNH fisica - verso\"\n",
        "}\n",
        "\n",
        "print(\"CLASSIFICAÇÃO FINAL:\", class_labels[classe_predita])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOHY8fxK7uFD",
        "outputId": "3d48151f-b44b-4423-bd3d-8b175d3f410f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagem processada.\n",
            "CLASSIFICAÇÃO FINAL: CNH fisica - aberta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confira visualmente se a classificação foi assertiva\n",
        "plt.imshow(image_to_process)"
      ],
      "metadata": {
        "id": "FHgwduJE1jOO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}